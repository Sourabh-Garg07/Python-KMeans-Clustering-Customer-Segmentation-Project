{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r\"C:\\Users\\hinaj\\OneDrive\\Documents\\Project datasets\\online_retail_II.xlsx\", sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING COPY OF THE ORIGINAL DATASET\n",
    "\n",
    "df = data.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL DESCRIPTION OF DATASET\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING ALL COLUMNS OF THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOKING AT MISSING CUSTOMER ID\n",
    "\n",
    "df[df['Customer ID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A LOOK AT NEGATIVE QUANTITIES \n",
    "\n",
    "df[df['Quantity'] < 0].head(10)\n",
    "\n",
    "## Most of the Data does have Customer ID and looks valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A LOOK AT NEGATIVE PRICE\n",
    "\n",
    "df[df['Price'] < 0]\n",
    "\n",
    "## These are data with bad debts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOKING AT CANCELLED INVOICE (STARTS WITH LETTER 'C' IN THE BEGINNING OF INVOICE)\n",
    "\n",
    "df['Invoice'] = df['Invoice'].astype('str')\n",
    "df[df['Invoice'].str.match('^\\\\d{6}$') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECKING IF INVOICES CONTAIN OTHER ALPHABETS\n",
    "\n",
    "df['Invoice'].str.replace('[0-9]', '', regex=True).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Invoice'].str.startswith('A')]\n",
    "\n",
    "## Invoice starting with A specifies bad debt accounts of the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECKING STOCKCODE COLUMN (5digits + Alphabet)\n",
    "\n",
    "df['StockCode'].astype('str')\n",
    "df[(df['StockCode'].str.match('^\\\\d{5}$') == False) & (df['StockCode'].str.match('^\\\\d{5}[a-zA-Z]+$') == False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOKING AT DISTINCT STOCK CODE VALUES\n",
    "\n",
    "df[(df['StockCode'].str.match('^\\\\d{5}$') == False) & (df['StockCode'].str.match('^\\\\d{5}[a-zA-Z]+$') == False)]['StockCode'].unique() \n",
    "\n",
    "## These stock codes specify different charges incurred by store which do not hold any significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOKING AT COUNTRY COLUMN \n",
    "\n",
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOKING EIRE COUNTRY\n",
    "\n",
    "df[df['Country'].str.contains('EIRE')]\n",
    "\n",
    "## Data does not contain any problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOKING AT UNSPECIFIED COUNTRY\n",
    "\n",
    "df[df['Country'].str.contains('Unspecified')]\n",
    "\n",
    "## Data does not contain any problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STARTING DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVING UNWANTED VALUES FROM INVOICE COLUMN \n",
    "\n",
    "df['Invoice'] = df['Invoice'].astype('str')\n",
    "\n",
    "mask = (\n",
    "    df['Invoice'].str.match('^\\\\d{6}$') == True\n",
    ")\n",
    "\n",
    "df = df[mask]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVING UNWANTED VALUES FROM STOCK CODE COLUMN\n",
    "\n",
    "df['StockCode'] = df['StockCode'].astype('str')\n",
    "\n",
    "mask = (\n",
    "    (df['StockCode'].str.match('^\\\\d{5}$') == True )\n",
    "    | (df['StockCode'].str.match('^\\\\d{5}[a-zA-Z]+$') == True)\n",
    "    | (df['StockCode'].str.match('^PADS$') == True)\n",
    ")\n",
    "\n",
    "df = df[mask]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DROPIING NULLS FROM CUSTOMER ID \n",
    "\n",
    "df.dropna(subset='Customer ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOKING AT 0 PRICE VALUES \n",
    "\n",
    "len(df[df['Price'] == 0])\n",
    "\n",
    "## 28 values with 0 price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVING 0 PRICE VALUES \n",
    "\n",
    "df = df[df['Price'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECKING NUMBER OF DROPPED DATASET\n",
    "\n",
    "len(df)/len(data)\n",
    "\n",
    "## 77% of data is compatable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DROPPED 23% OF UNWANTED DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING SALES ANALYSIS \n",
    "\n",
    "df['Sales'] = df['Price'] * df['Quantity']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = df.groupby(by='Customer ID', as_index=False) \\\n",
    "    .agg(\n",
    "        MonetaryValue=('Sales', 'sum'),\n",
    "        Frequency=('Invoice', 'nunique'),\n",
    "        LastInvoiceDate=('InvoiceDate', 'max')\n",
    "    )\n",
    "\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_invoice_date = aggregated_df['LastInvoiceDate'].max()\n",
    "aggregated_df['Recency'] = (max_invoice_date - aggregated_df['LastInvoiceDate']).dt.days\n",
    "aggregated_df\n",
    "\n",
    "## Last date (2012-12-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECKING OUTLIERS IN THE DATASET (THROUGH BOX PLOT)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(data=aggregated_df['MonetaryValue'], color='blue')\n",
    "plt.title('Monetary Value Plot')\n",
    "plt.xlabel('Monetary value')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(data=aggregated_df['Frequency'], color='green')\n",
    "plt.title('Frequency Value Plot')\n",
    "plt.xlabel('Frequency value')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(data=aggregated_df['Recency'], color='pink')\n",
    "plt.title('Recency Value Plot')\n",
    "plt.xlabel('Recency value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Monetary value and frequency value has lots of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEPERATING OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTLIERS IN MONETARY VALUE\n",
    "\n",
    "M_Q1 = aggregated_df['MonetaryValue'].quantile(0.25)\n",
    "M_Q3 = aggregated_df['MonetaryValue'].quantile(0.75)\n",
    "\n",
    "M_IQR = (M_Q3 - M_Q1)\n",
    "\n",
    "Monetary_outliers_df = aggregated_df[(aggregated_df['MonetaryValue'] > (M_Q3 + 1.5*M_IQR)) | (aggregated_df['MonetaryValue'] < (M_Q1 - 1.5*M_IQR))].copy()\n",
    "Monetary_outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Monetary_outliers_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTLIERS IN FREQUENCY VALUES\n",
    "\n",
    "F_Q1 = aggregated_df['Frequency'].quantile(0.25)\n",
    "F_Q3 = aggregated_df['Frequency'].quantile(0.75)\n",
    "\n",
    "F_IQR = (F_Q3 - F_Q1)\n",
    "\n",
    "Frequency_outliers_df = aggregated_df[(aggregated_df['Frequency'] > (F_Q3 + 1.5*F_IQR)) | (aggregated_df['Frequency'] < (F_Q1 - 1.5*F_IQR))].copy()\n",
    "Frequency_outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frequency_outliers_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING NEW DATASET WITHOUT OUTLIERS \n",
    "\n",
    "Non_outliers_df = aggregated_df[(~aggregated_df.index.isin(Monetary_outliers_df.index)) & (~aggregated_df.index.isin(Frequency_outliers_df.index))]\n",
    "Non_outliers_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING NON OUTLIERS DATASET\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "a = fig.add_subplot(projection ='3d')\n",
    "scatter = a.scatter(Non_outliers_df['MonetaryValue'], Non_outliers_df['Frequency'], Non_outliers_df['Recency'])\n",
    "\n",
    "a.set_xlabel('Monetary value')\n",
    "a.set_ylabel('Frequency')\n",
    "a.set_zlabel('Recency')\n",
    "\n",
    "a.set_title('3D plot of Customer data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTING LIBRARIES FOR CLUSTERING ANALYSIS \n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.options.display.float_format = '{:20.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "\n",
    "scaled_data = scalar.fit_transform(Non_outliers_df[['MonetaryValue', 'Frequency', 'Recency']])\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(scaled_data, index=Non_outliers_df.index, columns=('Monetary values', 'Frequency', 'Recency'))\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING WITH STANDARDIZE VALUES \n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "a = fig.add_subplot(projection ='3d')\n",
    "scatter = a.scatter(scaled_df['Monetary values'], scaled_df['Frequency'], scaled_df['Recency'])\n",
    "\n",
    "a.set_xlabel('Monetary value')\n",
    "a.set_ylabel('Frequency')\n",
    "a.set_zlabel('Recency')\n",
    "\n",
    "a.set_title('3D plot of Customer data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMEANS CLUSTERING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOKING FOR SUITABLE NUMBER OF CLUSTERS\n",
    "\n",
    "max_k = 12 \n",
    "inertia = []\n",
    "k_values = range(2, max_k+1)\n",
    "\n",
    "for k in k_values:\n",
    "    \n",
    "    k_means = KMeans(n_clusters=k, random_state=42, max_iter=1000)\n",
    "    k_means.fit_predict(scaled_df)\n",
    "    inertia.append(k_means.inertia_)\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "\n",
    "plt.title('kMeans inertia values')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## 4 Number of clusters looked appropriate for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETTING CLUSTERS IN DATAFRAME\n",
    "\n",
    "k_means = KMeans(n_clusters=4, random_state=42, max_iter=1000)\n",
    "cluster_labels = k_means.fit_predict(scaled_df)\n",
    "\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_outliers_df['clusters'] = cluster_labels\n",
    "Non_outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING CLUSTER \n",
    "\n",
    "cluster_colors = {0: '#1f77b4', #Blue\n",
    "                  1:'#ff7f0e',   #Orange\n",
    "                  2: '#2ca02c', #Green\n",
    "                  3: '#d62728'} #Red\n",
    "\n",
    "colors = Non_outliers_df['clusters'].map(cluster_colors)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(Non_outliers_df['MonetaryValue'], \n",
    "                     Non_outliers_df['Frequency'], \n",
    "                     Non_outliers_df['Recency'], \n",
    "                     c=colors, # Use mapped solid colors \n",
    "                     marker='o')\n",
    "\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "\n",
    "ax.set_title('3D Scatter Plot of Customer Data by cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLUSTER ANALYSIS \n",
    "\n",
    "Cluster 0 (Blue) = Regular Buyers with moderate monetary values and high frequency = 'Promotion'\n",
    "Cluster 1 (Orange) = Old Buyers with moderate frequency but have not purchased since long = 'Re-Engage'\n",
    "Cluster 2 (Green) = New Buyers with less monetary value = 'Engagement'\n",
    "Cluster 3 (Red) = Buyers with very high monetary value and high frequency = 'Loyal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTLIERS CLUSTERS \n",
    "\n",
    "overlap_indices = Monetary_outliers_df.index.intersection(Frequency_outliers_df.index)\n",
    "overlap_indices\n",
    "\n",
    "Monetary_only_outliers_df = Monetary_outliers_df.drop(overlap_indices)\n",
    "Frequency_only_outliers_df = Frequency_outliers_df.drop(overlap_indices)\n",
    "Monetary_and_Frequency_outliers = Monetary_outliers_df.loc[overlap_indices]\n",
    "\n",
    "Monetary_only_outliers_df['clusters'] = -1\n",
    "Frequency_only_outliers_df['clusters'] = -2\n",
    "Monetary_and_Frequency_outliers['clusters'] = -3\n",
    "\n",
    "Outliers_df = pd.concat([Monetary_only_outliers_df, Frequency_only_outliers_df, Monetary_and_Frequency_outliers])\n",
    "Outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING OUTLIER CLUSTERS\n",
    "\n",
    "cluster_colors = {-1: '#9467bd',\n",
    "                  -2:'#8c564b',   \n",
    "                  -3: '#e377c2'} \n",
    "                  \n",
    "\n",
    "colors = Outliers_df['clusters'].map(cluster_colors)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(Outliers_df['MonetaryValue'], \n",
    "                     Outliers_df['Frequency'], \n",
    "                     Outliers_df['Recency'], \n",
    "                     c=colors, # Use mapped solid colors \n",
    "                     marker='o')\n",
    "\n",
    "ax.set_xlabel('MonetaryValue')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "\n",
    "ax.set_title('3D Scatter Plot of Outlier Data by cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTLIERS CLUSTER ANALYSIS \n",
    "\n",
    "Cluster -1 = High spendings but infrequent buyers = 'GetBack'\n",
    "Cluster -2 = High frequent but less monetary values = 'NeedDeals'\n",
    "Cluster -3 = High monetary value and high frequency = 'VIPs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINING CUTSOMERS IN DATASET \n",
    "\n",
    "cluster_labels = {\n",
    "    0:'RETAIN',\n",
    "    1:'RE-ENGAGE',\n",
    "    2:'NURTURE',\n",
    "    3:'REWARD',\n",
    "    -1:'PAMPER',\n",
    "    -2:'UPSELL',\n",
    "    -3:'DELIGHT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_cluster_df = pd.concat([Non_outliers_df, Outliers_df])\n",
    "Full_cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_cluster_df['ClusterLabels'] = Full_cluster_df['clusters'].map(cluster_labels)\n",
    "Full_cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_cluster_df.groupby(by='ClusterLabels').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
